{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 3: Bilinear Inverse Problems and Low-Rank Matrix Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x] By tick the checkbox, we hereby declare that this coursework report is our own and autonomous work. We have acknowledged all material and sources used in its preparation, including books, articles, reports, lecture notes, internet software packages, and any other kind of document, electronic or personal communication. This work has not been submitted for any other assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Test Data Generation (10%)\n",
    "\n",
    "We consider the low-rank matrix completion problem given by \n",
    "$$\n",
    "    \\bm{y} = \\mathcal{P}_{\\Omega}(\\bm{X}) \n",
    "$$\n",
    "where $\\bm{X} \\in \\mathbb{R}^{m \\times n}$ is a low rank matrix of rank $r$. \n",
    "\n",
    "Data generation: Write $\\bm{X} = \\bm{U} \\bm{G} \\bm{V}^{\\mathsf{T}}$, where $\\bm{U} \\in \\mathbb{R}^{m \\times r}$, $\\bm{G} \\in \\mathbb{R}^{r \\times r}$, and $\\bm{V} \\in \\mathbb{R}^{n \\times r}$ are matrices with i.i.d. $\\mathcal{N}(0,1)$ Gaussian entries. (Note that by $\\bm{X} = \\bm{U} \\bm{G} \\bm{V}^{\\mathsf{T}}$ we are not talking about SVD.)\n",
    "\n",
    "Design and implement a function `LRMC_data_gen` to generate test data. Provide necessary documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMC_data_gen (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using Plots\n",
    "\n",
    "function GaussianGen(m::Int64, n::Int64)\n",
    "    A = randn(Float64, m, n)\n",
    "    Norm = zeros(m,n)\n",
    "    for i = 1:n\n",
    "        Norm[:,i] = normalize(A[:,i], 2);\n",
    "    end\n",
    "    return Norm\n",
    "end\n",
    "\n",
    "function Create_linear_operator(Ω)\n",
    "    m, n = size(Ω)\n",
    "    idm = Matrix(1I, m*n, m*n)\n",
    "\n",
    "    cardinality = count(i->(i != false), vec(Ω))\n",
    "    A = Array{Int64, 2}(undef, cardinality, m*n)\n",
    "\n",
    "    idx = 1\n",
    "\n",
    "    for i = 1:m*n\n",
    "        if vec(Ω)[i] == true\n",
    "            A[idx, :] = idm[i, :]\n",
    "            idx += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return A\n",
    "end\n",
    "\n",
    "function Observation_samples(X::AbstractArray, m::Int64, n::Int64, samples::Int64)\n",
    "\n",
    "    random_indices = sample(randperm(m*n), samples, replace=false)\n",
    "\n",
    "    Ω = zeros(Bool, m, n)\n",
    "    Ω[random_indices] .= true\n",
    "\n",
    "    Y = zeros(m, n)\n",
    "\n",
    "    Y[Ω] = X[Ω]\n",
    "\n",
    "    return Y, Ω\n",
    "end\n",
    "\n",
    "function LRMC_data_gen(m::Int64, n::Int64, r::Int64)\n",
    "    U = GaussianGen(m, r)\n",
    "    G = GaussianGen(r, r)\n",
    "    V = GaussianGen(n, r)\n",
    "\n",
    "    X = U * G * V'\n",
    "\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Matrix Completion Techniques\n",
    "\n",
    "In the following, the suggested simulation setup is that $m = 32$, $n=48$, $r$ varies in $2:2:8$, and $|\\Omega|/mn$ varies in $\\{1/8,~ 1/6,~ 1/4,~ 1/2\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Alternating Minimization (20%)\n",
    "\n",
    "Design, implement, and run tests for the alternating minimization method for low-rank matrix completion. Use the function name `LRMCRec_AM`. Provide necessary documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMCRec_AM (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using Plots\n",
    "\n",
    "function Least_squares_P(Y, P, Ω)\n",
    "    r = size(P, 2)\n",
    "    m = size(Y, 1)\n",
    "    n = size(Y, 2)\n",
    "    \n",
    "    Q = Array{Float64, 2}(undef, n, r)\n",
    "\n",
    "    for i = 1:n\n",
    "        y = Y[:, i]\n",
    "        p = Array{Float64, 2}(undef, m, r)\n",
    "\n",
    "        for j = 1:r\n",
    "            p[:, j] = Ω[:, i] .* P[:, j] \n",
    "        end\n",
    "\n",
    "        Q'[:, i] = pinv(p) * y\n",
    "    end\n",
    "\n",
    "    return Q\n",
    "end\n",
    "\n",
    "function Least_squares_Q(Y, Q, Ω)\n",
    "    r = size(Q, 2)\n",
    "    m = size(Y, 1)\n",
    "    n = size(Y, 2)\n",
    "\n",
    "    P = Array{Float64, 2}(undef, m, r)\n",
    "\n",
    "    for i = 1:m\n",
    "        y = Y'[:, i]\n",
    "        q = Array{Float64, 2}(undef, n, r)\n",
    "\n",
    "        for j = 1:r\n",
    "            q[:, j] = Ω'[:, i] .* Q[:, j] \n",
    "        end\n",
    "\n",
    "        P'[:, i] = pinv(q) * y\n",
    "    end\n",
    "\n",
    "    return P\n",
    "end\n",
    "\n",
    "function Altmin(Y, P, Ω, iters)\n",
    "\n",
    "    Q = Least_squares_P(Y, P, Ω)\n",
    "    P = Least_squares_Q(Y, Q, Ω)\n",
    "    \n",
    "    for i = 1:iters-1\n",
    "        Q = Least_squares_P(Y, P, Ω)\n",
    "        P = Least_squares_Q(Y, Q, Ω)\n",
    "    end\n",
    "\n",
    "    return P, Q\n",
    "end\n",
    "\n",
    "function LRMCRec_AM(Y, Ω, r, iters)\n",
    "    m = size(Y, 1)\n",
    "    U, _, _ = svd(Y)\n",
    "    P = U[:, 1:r]\n",
    "\n",
    "    P_t, Q_t = Altmin(Y, P, Ω, iters)\n",
    "\n",
    "    X = P_t * Q_t'\n",
    "\n",
    "    return X\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×48 Matrix{Float64}:\n",
       " -0.0416941    -0.187313     0.00642348  …  -0.562936     0.259352\n",
       " -0.00131982   -0.00268662   0.00414451     -0.0708499    0.00046994\n",
       " -0.00455454   -0.0186716   -0.00614353     -0.00212967   0.0337777\n",
       "  0.0060761    -0.246116     0.0660126       0.252196    -0.162667\n",
       "  0.0160429     0.039618    -0.00340605      0.0304046   -0.0078738\n",
       "  0.0170226    -0.00751578   0.107588    …  -0.437306    -0.0118137\n",
       " -0.0806336     0.182507    -0.0367217       0.177678    -0.0937305\n",
       "  0.0274882     0.164393    -0.0207649       0.546753    -0.0927862\n",
       "  0.0766081     0.00646359   0.0483127       0.854538    -0.147075\n",
       "  0.00522084   -0.21703      0.0511019       0.0410749   -0.0328091\n",
       "  ⋮                                      ⋱               \n",
       " -0.0126735     0.171233    -0.0289607       0.0467297   -0.217098\n",
       " -0.00856316    0.25821     -0.0842809      -0.203098     0.104583\n",
       " -0.0362695     0.0390075    0.0183053   …   0.2999      -0.258449\n",
       " -0.0206781    -0.264268     0.0290492      -0.328523     0.21332\n",
       "  0.00964622    0.0373628    0.00990138      0.151278    -0.0753757\n",
       " -0.0446722    -0.212431     0.0176522      -0.586662     0.24524\n",
       " -0.000150967   0.00234985  -0.00381537      0.0770452   -0.0055511\n",
       "  0.0104545    -0.0834128    0.0281416   …  -0.234329    -0.107548\n",
       " -0.0260064    -0.106277     0.00122531     -0.115249     0.131771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X  = LRMC_data_gen(32, 48, 8)\n",
    "Y, Ω = Observation_samples(X, 32, 48, 196)\n",
    "\n",
    "X_predict = LRMCRec_AM(Y, Ω, 8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank(X_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Iterative Hard Thresholding (IHT) (20%)\n",
    "\n",
    "Design, implement, and run simple tests for the IHT algorithm for low-rank matrix completion. Use the function name `LRMCRec_IHT`. Provide necessary documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMCRec_IHT (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function r_rank_approx(M, r::Int)\n",
    "    U, Σ, V = svd(M)\n",
    "    N = length(Σ)\n",
    "\n",
    "    for i = r+1:N\n",
    "        Σ[i] = 0\n",
    "    end\n",
    "\n",
    "    return U * Diagonal(Σ) * V'\n",
    "end\n",
    "\n",
    "function r_rank_approx_1(M, r::Int)\n",
    "    # Gives a r rank approximation to the input matrix M \n",
    "    U, Sigma, V = svd(M)\n",
    "    r_rank_M = Sigma[1]*U[:,1]*transpose(V[:,1])\n",
    "\n",
    "    for i = 2:r\n",
    "        u = U[:,i]; v = V[:,i]; s = Sigma[i]\n",
    "        r_rank_M += s * u * transpose(v)\n",
    "    end\n",
    "\n",
    "    return r_rank_M\n",
    "end \n",
    "\n",
    "function LRMCRec_IHT(Y, Ω, r::Int, τ::Float64, iters::Int)\n",
    "    m, n = size(Y)\n",
    "    X = copy(Y)\n",
    "    \n",
    "    temp = zeros(m,n)   \n",
    "    error_list = []\n",
    "    num_iters = iters\n",
    "\n",
    "    while num_iters < 1000 \n",
    "        # Iteration algorithm to reduce objective error \n",
    "        temp[Ω] = Y[Ω] - X[Ω]\n",
    "        X  = r_rank_approx(X + τ*(temp), r)\n",
    "        \n",
    "        #Calculate objective error\n",
    "        error = norm(Y[Ω] - X[Ω],2)^2\n",
    "        append!(error_list,error)\n",
    "        \n",
    "        #Increase the number of iterations\n",
    "        num_iters = num_iters + 1\n",
    "\n",
    "    end \n",
    "    return X, 1:num_iters, error_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v = [0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 -0.19599300006446388 -0.18106175009308564 0.0; 0.07427507620716461 0.0 0.0 0.0 0.0 0.0; 0.0 0.10218265144524336 0.0 -4.3519188267385524e-17 -4.020378476645396e-17 0.0]\n",
      "p = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 -0.19599300006446388 -0.18106175009308564 0.0; 0.07427507620716461 0.0 0.0 0.0 0.0 0.0; 0.0 0.10218265144524336 0.0 -4.3519188267385524e-17 -4.020378476645396e-17 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×6 Matrix{Float64}:\n",
       " 0.0        0.0       0.0   0.0           0.0          0.0\n",
       " 0.0        0.0       0.0  -0.195993     -0.181062     0.0\n",
       " 0.0742751  0.0       0.0   0.0           0.0          0.0\n",
       " 0.0        0.102183  0.0  -4.35192e-17  -4.02038e-17  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Iterative Shrinkage-Thresholding Algorithm (ISTA) (25%)\n",
    "\n",
    "Design, implement, and run simple tests for ISTA (to solve the Lasso formulation) for low-rank matrix completion. Use the function name `LRMCRec_ISTA`. Provide necessary documentation. Use simulations to discuss the choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMCRec_ISTA (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using Plots\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "function nuclear_norm(X)\n",
    "    _, S, _ = svd(X)\n",
    "    return sum(S)\n",
    "end\n",
    "\n",
    "function current_error(X, Y, Ω, λ)\n",
    "    return 0.5 * norm(X[Ω] - Y[Ω])^2 + λ * nuclear_norm(X)\n",
    "end\n",
    "\n",
    "function Singular_value_soft_threshold(X, λ)\n",
    "    U, S, V = svd(X)\n",
    "    threshold = max.(S .- λ, 0.0)\n",
    "    return U * Diagonal(threshold) * V'\n",
    "end\n",
    "\n",
    "# Low Rank Matrix Completion Iterative Shrinkage Thresholding Algorithm.\n",
    "\n",
    "function LRMCRec_ISTA(Y, Ω, λ, iterations)\n",
    "    X = copy(Y)\n",
    "\n",
    "    error_list = zeros(iterations + 1)\n",
    "    error_list[1] = current_error(X, Y, Ω, λ)\n",
    "\n",
    "    for i=1:iterations\n",
    "        X[Ω] = Y[Ω]\n",
    "        X = Singular_value_soft_threshold(X, λ)\n",
    "\n",
    "        error_list[i+1] = current_error(X, Y, Ω, λ)\n",
    "    end\n",
    "\n",
    "    return X, error_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(X_predict - X) / norm(X) = 0.5759336318892304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5759336318892304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X  = LRMC_data_gen(32, 48, 8)\n",
    "Y, Ω = Observation_samples(X, 32, 48, 384)\n",
    "\n",
    "X_predict, error = LRMCRec_ISTA(Y, Ω, 0.01, 1000)\n",
    "\n",
    "@show norm(X_predict - X) / norm(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Lasso-ADMM (25%)\n",
    "\n",
    "Design, implement, and run simple tests for an ADMM algorithm (to solve the Lasso formulation) for low-rank matrix completion. Use the function name `LRMCRec_ADMM`. Provide necessary documentation. Compare ADMM and ISTA in terms of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight\n",
    "\n",
    "Please list a couple of highlights of your coursework that may impress your markers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
