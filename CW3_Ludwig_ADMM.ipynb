{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 3: Bilinear Inverse Problems and Low-Rank Matrix Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x] By tick the checkbox, we hereby declare that this coursework report is our own and autonomous work. We have acknowledged all material and sources used in its preparation, including books, articles, reports, lecture notes, internet software packages, and any other kind of document, electronic or personal communication. This work has not been submitted for any other assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Test Data Generation (10%)\n",
    "\n",
    "We consider the low-rank matrix completion problem given by \n",
    "$$\n",
    "    \\bm{y} = \\mathcal{P}_{\\Omega}(\\bm{X}) \n",
    "$$\n",
    "where $\\bm{X} \\in \\mathbb{R}^{m \\times n}$ is a low rank matrix of rank $r$. \n",
    "\n",
    "Data generation: Write $\\bm{X} = \\bm{U} \\bm{G} \\bm{V}^{\\mathsf{T}}$, where $\\bm{U} \\in \\mathbb{R}^{m \\times r}$, $\\bm{G} \\in \\mathbb{R}^{r \\times r}$, and $\\bm{V} \\in \\mathbb{R}^{n \\times r}$ are matrices with i.i.d. $\\mathcal{N}(0,1)$ Gaussian entries. (Note that by $\\bm{X} = \\bm{U} \\bm{G} \\bm{V}^{\\mathsf{T}}$ we are not talking about SVD.)\n",
    "\n",
    "Design and implement a function `LRMC_data_gen` to generate test data. Provide necessary documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMC_data_gen (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using Plots\n",
    "\n",
    "function GaussianGen(m::Int64, n::Int64)\n",
    "    A = randn(Float64, m, n)\n",
    "    Norm = zeros(m,n)\n",
    "    for i = 1:n\n",
    "        Norm[:,i] = normalize(A[:,i], 2);\n",
    "    end\n",
    "    return Norm\n",
    "end\n",
    "\n",
    "function Create_linear_operator(Ω)\n",
    "    m, n = size(Ω)\n",
    "    idm = Matrix(1I, m*n, m*n)\n",
    "\n",
    "    cardinality = count(i->(i != false), vec(Ω))\n",
    "    A = Array{Int64, 2}(undef, cardinality, m*n)\n",
    "\n",
    "    idx = 1\n",
    "\n",
    "    for i = 1:m*n\n",
    "        if vec(Ω)[i] == true\n",
    "            A[idx, :] = idm[i, :]\n",
    "            idx += 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return A\n",
    "end\n",
    "\n",
    "function Observation_samples(X::AbstractArray, m::Int64, n::Int64, samples::Int64)\n",
    "\n",
    "    random_indices = sample(randperm(m*n), samples, replace=false)\n",
    "\n",
    "    Ω = zeros(Bool, m, n)\n",
    "    Ω[random_indices] .= true\n",
    "\n",
    "    Y = zeros(m, n)\n",
    "\n",
    "    Y[Ω] = X[Ω]\n",
    "\n",
    "    return Y, Ω\n",
    "end\n",
    "\n",
    "function LRMC_data_gen(m::Int64, n::Int64, r::Int64)\n",
    "    U = GaussianGen(m, r)\n",
    "    G = GaussianGen(r, r)\n",
    "    V = GaussianGen(n, r)\n",
    "\n",
    "    X = U * G * V'\n",
    "\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Matrix Completion Techniques\n",
    "\n",
    "In the following, the suggested simulation setup is that $m = 32$, $n=48$, $r$ varies in $2:2:8$, and $|\\Omega|/mn$ varies in $\\{1/8,~ 1/6,~ 1/4,~ 1/2\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Alternating Minimization (20%)\n",
    "\n",
    "Design, implement, and run tests for the alternating minimization method for low-rank matrix completion. Use the function name `LRMCRec_AM`. Provide necessary documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Iterative Hard Thresholding (IHT) (20%)\n",
    "\n",
    "Design, implement, and run simple tests for the IHT algorithm for low-rank matrix completion. Use the function name `LRMCRec_IHT`. Provide necessary documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Iterative Shrinkage-Thresholding Algorithm (ISTA) (25%)\n",
    "\n",
    "Design, implement, and run simple tests for ISTA (to solve the Lasso formulation) for low-rank matrix completion. Use the function name `LRMCRec_ISTA`. Provide necessary documentation. Use simulations to discuss the choice of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Lasso-ADMM (25%)\n",
    "\n",
    "Design, implement, and run simple tests for an ADMM algorithm (to solve the Lasso formulation) for low-rank matrix completion. Use the function name `LRMCRec_ADMM`. Provide necessary documentation. Compare ADMM and ISTA in terms of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRMCRec_ADMM (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "function Singular_value_soft_threshold(X, λ)\n",
    "    U, S, V = svd(X)\n",
    "    threshold = max.(S .- λ, 0.0)\n",
    "    return U * Diagonal(threshold) * V'\n",
    "end\n",
    "\n",
    "function nuclear_norm(X)\n",
    "    _, S, _ = svd(X)\n",
    "    return sum(S)\n",
    "end\n",
    "\n",
    "function current_cost(X, Y, Ω, λ)\n",
    "    return 0.5 * norm(X[Ω] - Y[Ω])^2 + λ * nuclear_norm(X)\n",
    "end\n",
    "\n",
    "function LRMCRec_ADMM(Y, Ω, λ, τ, iters, error_diff_tresh)\n",
    "    X = copy(Y)\n",
    "    m, n = size(X)\n",
    "    \n",
    "    Z = zeros(Float64, m, n)\n",
    "    V = zeros(Float64, m, n)\n",
    "\n",
    "    cost_past = Inf\n",
    "    cost = Inf\n",
    "    counter = 0\n",
    "\n",
    "    while counter <= iters\n",
    "        Z = Singular_value_soft_threshold(X+V, λ/τ)\n",
    "        X = (Y + τ*(Z - V)) ./ (Ω .+ τ)\n",
    "        V += X\n",
    "        V -= Z\n",
    "\n",
    "        cost = current_cost(X, Y, Ω, λ)\n",
    "        counter += 1\n",
    "\n",
    "        if (cost_past - cost <= error_diff_tresh)\n",
    "            break\n",
    "        else\n",
    "            cost_past = cost\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return X, counter\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.1856532868190991 Iterations: 101\n"
     ]
    }
   ],
   "source": [
    "X  = LRMC_data_gen(32, 48, 4)\n",
    "Y, Ω = Observation_samples(X, 32, 48, 792)\n",
    "\n",
    "λ = 0.01\n",
    "τ = 1.0\n",
    "error_diff_tresh = 0.00001\n",
    "iters = 1000\n",
    "\n",
    "X_predict, counter = LRMCRec_ADMM(Y, Ω, λ, τ, 100, error_diff_tresh)\n",
    "\n",
    "error = norm(X_predict - X) / norm(X)\n",
    "println(\"Error: \", error, \" Iterations: \", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight\n",
    "\n",
    "Please list a couple of highlights of your coursework that may impress your markers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
